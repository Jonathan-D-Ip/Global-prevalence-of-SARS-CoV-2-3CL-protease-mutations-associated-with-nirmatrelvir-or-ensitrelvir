{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa36db02",
   "metadata": {},
   "source": [
    "### Mutations associated with resistance to Paxlovid treatment\n",
    "\n",
    "Here we investigate the global trends in mutations in the SARS-CoV-2 genome associated with resistance to Paxlovid treatment. We used [Iketani *et al.*](https://www.nature.com/articles/s41586-022-05514-2) as reference for the mutations. Global SARS-CoV-2 genome sequencing data was downloaded from [GISAID](https://gisaid.org/), and the processing carried out in Python. The code is given below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5059c94",
   "metadata": {},
   "source": [
    "### Import libraries, version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d6b00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code has been written and tested using the following libraries:\n",
      "Python v3.7.5 (default, Dec  9 2021, 17:04:37)\n",
      "[GCC 7.5.0]\n",
      "pandas v1.3.5\n",
      "numpy v1.21.6\n",
      "json v2.0.9\n",
      "openpyxl v3.0.10\n",
      "\n",
      "\n",
      "Libraries installed on this system are:\n",
      "Python v3.7.5 (default, Dec  9 2021, 17:04:37) \n",
      "[GCC 8.4.0]\n",
      "pandas v1.3.5\n",
      "numpy v1.21.6\n",
      "json v2.0.9\n",
      "openpyxl v3.0.10\n"
     ]
    }
   ],
   "source": [
    "# code written by Jonathan D. Ip on 30-Dec-2022 on a Linux based system\n",
    "# verified on a Windows 10 based system on 01-Jan-2023 and a\n",
    "# Ubuntu 22.04.1 LTS system on 03-Jan-2023 by S. M. Umer Abdullah \n",
    "# For queries please contact jdip1007@connect.hku.hk\n",
    "\n",
    "print('This code has been written and tested using the following libraries:')\n",
    "print('Python v3.7.5 (default, Dec  9 2021, 17:04:37)')\n",
    "print('[GCC 7.5.0]')\n",
    "print('pandas v1.3.5')\n",
    "print('numpy v1.21.6')\n",
    "print('json v2.0.9')\n",
    "print('openpyxl v3.0.10')\n",
    "print('\\n')\n",
    "print('Libraries installed on this system are:')\n",
    "import os\n",
    "import sys\n",
    "print('Python v%s' % sys.version)\n",
    "import pandas as pd\n",
    "print('pandas v%s' % pd.__version__)\n",
    "#from tqdm.auto import tqdm\n",
    "#import tqdm as tq\n",
    "#print('tqdm v%s' % tq.__version__)\n",
    "import numpy as np\n",
    "print('numpy v%s' % np.__version__)\n",
    "import json\n",
    "print('json v%s' % json.__version__)\n",
    "import openpyxl\n",
    "print('openpyxl v%s' % openpyxl.__version__)\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02183fe6",
   "metadata": {},
   "source": [
    "### Set input and output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e398890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder  = \"../data/\" ## input folder\n",
    "output_folder  = \"../output/\" ## output folder\n",
    "if(not os.path.isdir(output_folder)): ## check if output folder exists\n",
    "    os.mkdir(output_folder) ## create output folder if it does not exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8cc6ea",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90448683",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Collection date\", \"Type\", \"Location\", \"Pango lineage\", \"AA Substitutions\", \"Is complete?\", \"Host\",\\\n",
    "           \"Passage details/history\", \"Accession ID\"]\n",
    "\n",
    "ANY = \"__ANY__\" ## If the mutation list contains ANY as its first element, the strain containing any one of the included\n",
    "# mutations is considered\n",
    "\n",
    "## Mutations listed in Iketani et al.\n",
    "target_mut = [\n",
    "    \n",
    "    [\"NSP5_T21I\"], \n",
    "    [\"NSP5_P252L\"], \n",
    "    [\"NSP5_T304I\"],\n",
    "    [\"NSP5_E166V\"], \n",
    "    [\"NSP5_L50F\"], \n",
    "    [\"NSP5_S144A\"],\n",
    "    [\"NSP5_A173V\"],\n",
    "    [\"NSP5_T21I\", \"NSP5_E166V\"], \n",
    "    [\"NSP5_T21I\", \"NSP5_S144A\"], \n",
    "    [\"NSP5_L50F\", \"NSP5_E166V\"], \n",
    "    [\"NSP5_T21I\", \"NSP5_A173V\", \"NSP5_T304I\"],\n",
    "    [ANY, \"NSP5_T21I\",\"NSP5_P252L\",\"NSP5_T304I\",\"NSP5_E166V\",\"NSP5_S144A\"], ### Any of the mutations starting from the second element is considered\n",
    "    [ANY, \"NSP5_T21I\",\"NSP5_P252L\",\"NSP5_T304I\",\"NSP5_E166V\",\"NSP5_L50F\",\"NSP5_S144A\",\"NSP5_A173V\"],\n",
    "    \n",
    "## Mutations listed in other publications\n",
    "    [\"NSP5_G15S\"],\n",
    "    [\"NSP5_T45I\"],\n",
    "    [\"NSP5_D48Y\"],\n",
    "    [\"NSP5_M49T\"],\n",
    "    [\"NSP5_M49L\"],\n",
    "    [\"NSP5_M49I\"],\n",
    "    [\"NSP5_M49V\"],\n",
    "    [\"NSP5_Y54A\"],\n",
    "    [\"NSP5_Y54C\"],\n",
    "    [\"NSP5_T135I\"], \n",
    "    [\"NSP5_F140A\"],\n",
    "    [\"NSP5_F140L\"],\n",
    "    [\"NSP5_S144E\"],\n",
    "    [\"NSP5_S144T\"],\n",
    "    [\"NSP5_S144M\"],\n",
    "    [\"NSP5_S144F\"],\n",
    "    [\"NSP5_S144G\"],\n",
    "    [\"NSP5_S144Y\"],\n",
    "    [\"NSP5_H164N\"],\n",
    "    [\"NSP5_M165T\"],\n",
    "    [\"NSP5_E166A\"],\n",
    "    [\"NSP5_E166G\"],\n",
    "    [\"NSP5_E166V\"],\n",
    "    [\"NSP5_L167F\"],\n",
    "    [\"NSP5_P168del\"],\n",
    "    [\"NSP5_H172Y\"],\n",
    "    [\"NSP5_H172Q\"], \n",
    "    [\"NSP5_H172F\"],\n",
    "    [\"NSP5_A173T\"],\n",
    "    [\"NSP5_A173V\"],\n",
    "    [\"NSP5_V186G\"],\n",
    "    [\"NSP5_Q189K\"],\n",
    "    [\"NSP5_Q192L\"],\n",
    "    [\"NSP5_Q192P\"],\n",
    "    [\"NSP5_Q192T\"],\n",
    "    [\"NSP5_Q192S\"],\n",
    "    [\"NSP5_Q192A\"],\n",
    "    [\"NSP5_Q192I\"],\n",
    "    [\"NSP5_Q192H\"],\n",
    "    [\"NSP5_Q192V\"],\n",
    "    [\"NSP5_Q192W\"],\n",
    "    [\"NSP5_Q192C\"],\n",
    "    [\"NSP5_Q192F\"],\n",
    "    [\"NSP5_D248E\"],\n",
    "\n",
    "]\n",
    "\n",
    "any_of_all_mutations = [ANY,] + [ m[0] for m in target_mut if len(m) == 1 ]\n",
    "\n",
    "any_of_Affect_3CLpro_activity_affecting_mutations = [\n",
    "    ANY,\n",
    "    \"NSP5_G15S\",\n",
    "    \"NSP5_Y54A\",\n",
    "    \"NSP5_T135I\",\n",
    "    \"NSP5_F140A\",\n",
    "    \"NSP5_F140L\",\n",
    "    \"NSP5_S144E\",\n",
    "    \"NSP5_S144G\",\n",
    "    \"NSP5_S144M\",\n",
    "    \"NSP5_S144Y\",\n",
    "    \"NSP5_S144T\",\n",
    "    \"NSP5_H164N\",\n",
    "    \"NSP5_M165T\",\n",
    "    \"NSP5_E166G\",\n",
    "    \"NSP5_H172Q\",\n",
    "    \"NSP5_H172F\",\n",
    "    \"NSP5_V186G\",\n",
    "    \"NSP5_Q189K\",\n",
    "    \"NSP5_Q192T\",\n",
    "    \"NSP5_Q192S\",\n",
    "    \"NSP5_Q192A\",\n",
    "    \"NSP5_Q192I\",\n",
    "    \"NSP5_Q192H\",\n",
    "    \"NSP5_Q192V\",\n",
    "    \"NSP5_Q192W\",\n",
    "    \"NSP5_Q192C\",\n",
    "    \"NSP5_Q192F\",\n",
    "    \"NSP5_D248E\"\n",
    "]\n",
    "\n",
    "any_of_Reduction_of_SARS_CoV_2_replication_AND_mutations = [\n",
    "    ANY,\n",
    "    \"NSP5_S144A\",\n",
    "    \"NSP5_E166A\",\n",
    "    \"NSP5_H172Y\",\n",
    "    \"NSP5_A173V\",\n",
    "    \"NSP5_Q192L\",\n",
    "    \"NSP5_Q192P\",\n",
    "]\n",
    "\n",
    "any_of_Reduction_of_SARS_CoV_2_replication = [\n",
    "    ANY,\n",
    "    \"NSP5_T21I\",\n",
    "    \"NSP5_T45I\",\n",
    "    \"NSP5_D48Y\",\n",
    "    \"NSP5_M49I\",\n",
    "    \"NSP5_M49L\",\n",
    "    \"NSP5_M49T\",\n",
    "    \"NSP5_M49V\",\n",
    
    "    \"NSP5_L50F\",\n",
    "    \"NSP5_Y54C\",\n",
    "    \"NSP5_S144A\",\n",
    "    \"NSP5_E166V\",\n",
    "    \"NSP5_L167F\",\n",
    "    \"NSP5_P168del\",\n",
    "    \"NSP5_A173T\",\n",
    "    \"NSP5_A173V\",\n",
    "    \"NSP5_P252L\",\n",
    "    \"NSP5_T304I\",\n",
    "]\n",
    "\n",
    "target_mut.append(any_of_all_mutations)\n",
    "target_mut.append(any_of_Affect_3CLpro_activity_affecting_mutations)\n",
    "target_mut.append(any_of_Reduction_of_SARS_CoV_2_replication_AND_mutations)\n",
    "\n",
    "target_lineage = [\n",
    "    \"B.1.1.318\", ## includes AZ\n",
    "    \"B.1.1.7\", ## VOC Alpha\n",
    "    \"B.1.1.529\", ## VOC Omicron\n",
    "    \"B.1.351\", ## VOC Beta\n",
    "    \"B.1.1.28.1\", ## VOC Gamma\n",
    "    \"B.1.617.2\", ## VOC Delta\n",
    "    \"B.1.1.529.5.3.1.1.1.1.1\", ## VOC Omicron sublineage BQ.1\n",
    "    \"XBB\", ## VOC Omicron sublineage XBB\n",
    "    \"B.1.1.529.1\", ## VOC Omicron sublineage BA.1\n",
    "    \"B.1.1.529.2\", ## VOC Omicron sublineage BA.2\n",
    "    \"B.1.1.529.4\", ## VOC Omicron sublineage BA.4\n",
    "    \"B.1.1.529.5\", ## VOC Omicron sublineage BA.5\n",
    "    \"B.1.1.529.2.75\", ## VOC Omicron sublineage BA.2.75\n",
    "    \"B.1.1.1\", ## Has G15S as defining mutation\n",
    "]\n",
    "\n",
    "groupby_period = 'Collection Quarter' ## Group sequences by quarter of collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ede9f",
   "metadata": {},
   "source": [
    "### Read data and filter sequences based on completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525a6456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb9e17abed34b0f9fa98c03c354915a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total, complete = 0, 0 # keep count of total sequences, and sequences which fit our criterion of being complete\n",
    "res_df = pd.DataFrame()\n",
    "# parse over input file taking in 1e4 sequences in each pass\n",
    "for chunk in tqdm(pd.read_csv(input_folder+\"metadata.tsv\", header=0, sep='\\t', chunksize=10000)):\n",
    "    chunk = chunk[columns]\n",
    "    total += len(chunk)\n",
    "    chunk = chunk[chunk[\"Is complete?\"] == True]\n",
    "    chunk = chunk[chunk[\"Host\"] == \"Human\"]\n",
    "    chunk = chunk[chunk[\"Type\"] == \"betacoronavirus\"]\n",
    "    chunk = chunk[chunk[\"Passage details/history\"] == \"Original\"]\n",
    "    chunk = chunk[[\"Collection date\", \"Location\", \"Pango lineage\", \"AA Substitutions\", \"Accession ID\"]]\n",
    "    complete += len(chunk)\n",
    "    #print(total, complete)\n",
    "    res_df = pd.concat([res_df, chunk])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11846a8",
   "metadata": {},
   "source": [
    "### Print total number of sequences, and number of complete sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f377f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sequences in the GISAID metadata file: 14157266\n",
      "Number of complete sequences in the GISAID metadata file: 13770074\n"
     ]
    }
   ],
   "source": [
    "print('Total number of sequences in the GISAID metadata file: '+str(total))\n",
    "print('Number of complete sequences in the GISAID metadata file: '+str(complete))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f09cb5",
   "metadata": {},
   "source": [
    "### Filter sequences with complete collection date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "163651e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep complete collection dates with year, month, and day\n",
    "def reformat_date(date_strings):\n",
    "    if date_strings.count('-') == 2: # date value with 2 hyphens means complete day, month, and year\n",
    "        return date_strings\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "res_df[\"Collection date\"] = res_df[\"Collection date\"].apply(reformat_date)\n",
    "res_df.dropna(subset=[\"Collection date\",], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6c0090",
   "metadata": {},
   "source": [
    "### Print final number of sequences used for subsequent processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9327e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences with complete date of collection: 13446588\n"
     ]
    }
   ],
   "source": [
    "print('Number of sequences with complete date of collection: '+str(len(res_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2961eae",
   "metadata": {},
   "source": [
    "### Group dates by week, quarter, and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0361b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed_1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "res_df[\"Collection date\"] = pd.to_datetime(res_df[\"Collection date\"], format='%Y/%m/%d')\n",
    "res_df[\"Collection Week\"] = res_df[\"Collection date\"].dt.to_period(freq = 'W')  \n",
    "res_df[\"Collection Quarter\"] = res_df[\"Collection date\"].dt.to_period(freq = 'Q')  \n",
    "res_df[\"Collection Month\"] = res_df[\"Collection date\"].dt.to_period(freq = 'M')  \n",
    "\n",
    "res_df.sort_values(by=[groupby_period], inplace=True)\n",
    "res_df[\"Accession ID\"].to_csv(output_folder+\"accession_id.txt\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32da43e",
   "metadata": {},
   "source": [
    "### Output the counts of mutations associated with resistance to paxlovid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mut_freq = {}\n",
    "Dates = []\n",
    "# parse over all mutations of interest\n",
    "for tmuts in tqdm(target_mut):\n",
    "    if tmuts[0] == ANY:\n",
    "        tmut_name = \"Any of \"+\",\".join(tmuts[1:])\n",
    "    else:\n",
    "        tmut_name = \",\".join(tmuts)\n",
    "        \n",
    "    target_mut_freq[tmut_name] = []\n",
    "    for name, group_df in res_df.groupby([groupby_period]):\n",
    "        target_mut_freq[tmut_name].append(0)\n",
    "        for muts in group_df[\"AA Substitutions\"]:\n",
    "            if tmuts[0] != ANY:\n",
    "                if all([tmut in muts for tmut in tmuts]):\n",
    "                    target_mut_freq[tmut_name][-1] += 1\n",
    "            else:\n",
    "                if any([tmut in muts for tmut in tmuts[1:]]):\n",
    "                    target_mut_freq[tmut_name][-1] += 1\n",
    "        \n",
    "seq_count = []\n",
    "for name, group_df in tqdm(res_df.groupby([groupby_period])):\n",
    "    Dates.append(name.to_timestamp().date())\n",
    "    seq_count.append(len(group_df))\n",
    "    \n",
    "df = pd.DataFrame(target_mut_freq)\n",
    "df.index = Dates\n",
    "df[\"Sequence count\"] = seq_count\n",
    "df.loc['Total']= df.sum()\n",
    "df.to_csv(output_folder+\"Paxlovid_mutation.csv\", sep=',', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2303d6ad",
   "metadata": {},
   "source": [
    "### Group mutations appearing in individual continents and countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aca2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Continent(location):\n",
    "    return location.split('/')[0].strip()\n",
    "\n",
    "def get_Country(location):\n",
    "    return location.split('/')[1].strip()\n",
    "\n",
    "res_df[\"Continent\"] = res_df[\"Location\"].apply(get_Continent)\n",
    "res_df[\"Country\"] = res_df[\"Location\"].apply(get_Country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae3e3e",
   "metadata": {},
   "source": [
    "### Output the counts of mutations appearing in individual continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d980f40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prevalence_columns = []\n",
    "# parse over all mutations of interest\n",
    "for tmuts in tqdm(target_mut):\n",
    "    \n",
    "    tmp_df = res_df.copy()\n",
    "    \n",
    "    if tmuts[0] == ANY:\n",
    "        tmut_name = \"Any of \"+\",\".join(tmuts[1:])\n",
    "        tmp_df = tmp_df[tmp_df[\"AA Substitutions\"].str.contains('|'.join(tmuts[1:]))]\n",
    "    else:\n",
    "        tmut_name = \",\".join(tmuts)\n",
    "        for tmut in tmuts:\n",
    "            tmp_df = tmp_df[tmp_df['AA Substitutions'].str.contains(tmut)]\n",
    "        \n",
    "    tmp_series = tmp_df[\"Continent\"].value_counts()\n",
    "    tmp_series = tmp_series.rename(tmut_name)\n",
    "    prevalence_columns.append(tmp_series)\n",
    "    \n",
    "prevalence_continent_df = pd.concat(prevalence_columns,axis=1)\n",
    "prevalence_continent_df[\"Sequence count\"] = res_df[\"Continent\"].value_counts()\n",
    "prevalence_continent_df.to_csv(output_folder+\"Continent_prevalence.csv\", sep=',', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f927548",
   "metadata": {},
   "source": [
    "### Output the counts of mutations appearing in individual countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae5b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence_columns = []\n",
    "# parse over all mutations of interest\n",
    "for tmuts in tqdm(target_mut):\n",
    "    tmp_df = res_df.copy()\n",
    "    \n",
    "    if tmuts[0] == ANY:\n",
    "        tmut_name = \"Any of \"+\",\".join(tmuts[1:])\n",
    "        tmp_df = tmp_df[tmp_df[\"AA Substitutions\"].str.contains('|'.join(tmuts[1:]))]\n",
    "    else:\n",
    "        tmut_name = \",\".join(tmuts)\n",
    "        for tmut in tmuts:\n",
    "            tmp_df = tmp_df[tmp_df['AA Substitutions'].str.contains(tmut)]\n",
    "            \n",
    "    tmp_series = tmp_df[\"Country\"].value_counts()\n",
    "    tmp_series = tmp_series.rename(tmut_name)\n",
    "    prevalence_columns.append(tmp_series)\n",
    "    \n",
    "prevalence_country_df = pd.concat(prevalence_columns,axis=1)\n",
    "prevalence_country_df[\"Sequence count\"] = res_df[\"Country\"].value_counts()\n",
    "tmp_df = None\n",
    "prevalence_country_df.to_csv(output_folder+\"Country_prevalence.csv\", sep=',', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289eca4",
   "metadata": {},
   "source": [
    "### Output the counts of mutations appearing in specific lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence_columns = []\n",
    "# parse over all mutations of interest\n",
    "for tmuts in tqdm(target_mut):\n",
    "    tmp_df = res_df.copy()\n",
    "\n",
    "    if tmuts[0] == ANY:\n",
    "        tmut_name = \"Any of \"+\",\".join(tmuts[1:])\n",
    "        tmp_df = tmp_df[tmp_df[\"AA Substitutions\"].str.contains('|'.join(tmuts[1:]))]\n",
    "    else:\n",
    "        tmut_name = \",\".join(tmuts)\n",
    "        for tmut in tmuts:\n",
    "            tmp_df = tmp_df[tmp_df['AA Substitutions'].str.contains(tmut)]\n",
    "    \n",
    "    tmp_series = tmp_df[\"Pango lineage\"].value_counts()\n",
    "    tmp_series = tmp_series.rename(tmut_name)\n",
    "    prevalence_columns.append(tmp_series)\n",
    "    \n",
    "prevalence_lineage_df = pd.concat(prevalence_columns,axis=1)\n",
    "prevalence_lineage_df[\"Sequence count\"] = res_df[\"Pango lineage\"].value_counts()\n",
    "prevalence_lineage_df.to_csv(output_folder+f\"Lineage_prevalence.csv\", sep=',', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea1208",
   "metadata": {},
   "source": [
    "### Convert lineages into the original notation to easily incorporate sublineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd185de",
   "metadata": {},
   "outputs": [],
   "source": [
    "alias = {}\n",
    " \n",
    "# Opening JSON file\n",
    "with open(input_folder+'alias_key.json') as json_file: ## https://github.com/cov-lineages/pango-designation/blob/master/pango_designation/alias_key.json\n",
    "    alias = json.load(json_file)\n",
    "    \n",
    "def convert_lineages(lineage):\n",
    "    if lineage.split('.')[0] in alias:\n",
    "        return lineage.replace(lineage.split('.')[0], alias[lineage.split('.')[0]])\n",
    "    return lineage\n",
    "\n",
    "### Break down lineages into the most basic form for easy selection\n",
    "res_df[\"Detailed lineage\"] = res_df[\"Pango lineage\"].apply(convert_lineages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c2dcc",
   "metadata": {},
   "source": [
    "### Extract the accession numbers of the 13 strains with NSP5_E166V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64690812",
   "metadata": {},
   "outputs": [],
   "source": [
    "for accid, lineage, mut in zip(res_df[\"Accession ID\"], res_df[\"Detailed lineage\"], res_df['AA Substitutions']):\n",
    "    if \"NSP5_E166V\" in mut:\n",
    "        print(accid, lineage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b279382a",
   "metadata": {},
   "source": [
    "### Extract the accession numbers strains with both E166V and L50F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1823b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "for accid, lineage, mut in tqdm(zip(res_df[\"Accession ID\"], res_df[\"Detailed lineage\"], res_df['AA Substitutions'])):\n",
    "    if \"NSP5_E166V\" in mut and \"NSP5_L50F\" in mut:\n",
    "        print(accid, lineage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80985a19",
   "metadata": {},
   "source": [
    "### Combine all the output CSVs into one xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390aa552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import glob \n",
    "#!pip install xlsxwriter\n",
    "#!pip install openpyxl\n",
    "#import openpyxl, os\n",
    "\n",
    "if os.path.exists(output_folder+'database.xlsx'):\n",
    "    os.remove(output_folder+'database.xlsx')\n",
    "\n",
    "openpyxl.Workbook().save(output_folder+'database.xlsx')\n",
    "writer = pd.ExcelWriter(output_folder+'database.xlsx', engine='xlsxwriter')\n",
    "\n",
    "f = output_folder+\"Lineage_trend.csv\"\n",
    "df = pd.read_csv(f)\n",
    "df.to_excel(writer, index=False, sheet_name=f\"Lineage trend (raw)\")\n",
    "\n",
    "f = output_folder+\"Lineage_prevalence.csv\"\n",
    "df = pd.read_csv(f)\n",
    "df.to_excel(writer, index=False, sheet_name=f\"Lineage prev. (raw)\")\n",
    "\n",
    "f = output_folder+\"Paxlovid_mutation.csv\"\n",
    "df = pd.read_csv(f)\n",
    "df.to_excel(writer, index=False, sheet_name=f\"Paxlovid mutation (raw)\")\n",
    "\n",
    "f = output_folder+\"Continent_prevalence.csv\"\n",
    "df = pd.read_csv(f)\n",
    "df.to_excel(writer, index=False, sheet_name=f\"Continent prev. (raw)\")\n",
    "\n",
    "f = output_folder+\"Country_prevalence.csv\"\n",
    "df = pd.read_csv(f)\n",
    "df.to_excel(writer, index=False, sheet_name=f\"Country prev. (raw)\")\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada001b",
   "metadata": {},
   "source": [
    "### Count number of strains containing the 3CLpro inhibitor affecting mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e40ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_number_of_sequences_with_mutations = 0 \n",
    "with open(output_folder+'accession_number_with_mutations.txt', 'w') as fw:\n",
    "    for accid, muts in tqdm(zip(res_df[\"Accession ID\"], res_df['AA Substitutions'])):\n",
    "        if any([tmut in muts for tmut in any_of_all_mutations[1:]]):\n",
    "            fw.write(accid+'\\n')\n",
    "            Total_number_of_sequences_with_mutations += 1\n",
    "print(f\"Total_number_of_sequences_with_mutations:: {Total_number_of_sequences_with_mutations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067fcb84",
   "metadata": {},
   "source": [
    "### Export a table containing information of the strains carrying the 3CLpro inhibitor affecting mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c465a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accession_id = []\n",
    "location     = []\n",
    "collection_d = []\n",
    "\n",
    "for accid, muts, cdate, location in tqdm(zip(res_df[\"Accession ID\"], res_df['AA Substitutions'], res_df['Collection date'], res_df['Location'])):\n",
    "    if any([tmut in muts for tmut in any_of_all_mutations[1:]]):\n",
    "        accession_id.append()\n",
    "        location.append()\n",
    "        collection_d.append()\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Accession ID': accession_id,\n",
    "    'Location': location,\n",
    "    'Collection Date': collection_d,\n",
    "}).to_csv(output_folder+\"strain_info_table.csv\", sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
